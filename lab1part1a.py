# -*- coding: utf-8 -*-
"""pytorch_tutorial.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kj5R_EYxKTXdjcqjWLDqlvVckj23QICY

Import modules and set up the environment. When using colab, all common libraries such as pytorch, numpy, etc. are already installed in the server, you don't need to worry about environment setup and directly import the libraries.
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
import time

import torch
import torch.nn as nn
print("CUDA available:", torch.cuda.is_available())


"""Now let's select GPU to train the model by setting the device parameter. Pytorch provides a free GPU for you to use."""

device = 'cuda' if torch.cuda.is_available() else 'cpu' #set the 'device' to GPU if a GPU is detected, otherwise set to CPU
print('Using {} device'.format(device))

"""Define the data transformations and load the CIFAR-10 dataset"""

transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=0)

testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=0)

classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')

"""Define a custom simple neural network (LeNet-like). You need to read Pytorch's documentation of nn.Conv2d to understand waht do the input parameters mean. Here we define a simple 5-layer CNN with 2 convolution layers and 2 fully connected layers."""

class SimpleNet(nn.Module):
    def __init__(self):
        super(SimpleNet, self).__init__()
        #note that conv2d has parameters (inchannels, outchannles, kernel_size, stride, padding)
        #in channles is the number of input channels
        #out channels is the number of output channles, or the number of filters
        #the kernel size is the size of the filter

        #note that Output size= [(input size + (2xpadding) - kernel size)/stride] + 1
        self.conv1 = nn.Conv2d(3, 32, 3, padding = 1) #first channel must set to 3 for this dataset as it has three color channels
        #think of the above as 32 cubes, each with depth 3 (first parameter) and height and width 3x3 (third parameter)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(32, 32, 3, padding = 1) #this is 32 filter cubes (2nd parameter) with depth 32 (first parameter) of size 3x3
        self.fc1 = nn.Linear(64 * 4 * 4, 120) #(infeatures, outfeatures) --> y = Wx + b, this just automatically caluclates the size of W
        self.fc2 = nn.Linear(120, 10)
        self.conv3 = nn.Conv2d(32, 64, 3, padding=1) #third convolutional layer with 32 input channels and 64 output channels 
        self.bn1 = nn.BatchNorm2d(32)
        self.bn2 = nn.BatchNorm2d(32)
        self.bn3 = nn.BatchNorm2d(64)



    def forward(self, x):
        #the input x is [N, 3, 32, 32] --> think of this as N cubes with depth 3, height 32, width 32
        x = self.conv1(x)
        x = self.pool(x)
        x = self.bn1(x)
        x = torch.relu(x)

        x = self.conv2(x)
        x = self.pool(x)
        x = self.bn2(x)
        x = torch.relu(x)

        x = self.conv3(x)
        x = self.pool(x)
        s = self.bn3(x)
        x = torch.relu(x)

        #same size, max(0,1) --> [N, 32, 16, 16]
        x = x.view(-1, 64 * 4 * 4) #Reshape the convolution output for the FC layers
        # keeps N the same, --> [N, 2048]
        x = torch.relu(self.fc1(x))
        x = self.fc2(x)
        #now it is just taking 120 and shaping it to 10 classes or features!
        return x
        #after conv1 it will keep the height and width due to padding, think of 3 as the depth which dissapears
        #we know we have 32 filters, so now we get N, 32, _, _ 
        # Output size= [(input size + (2xpadding) - kernel size)/stride] + 1
        #output size = [(32 + (2x1) - 3)/1 + 1] = 34-3 + 1 = 32
        #there are now 32 filters still with 32x32 height and width --> imagine 32 3x3x3 cubes sliding over a 32x32x3 cube
        #the shape is now [N, 32, 32, 32]
        #note that the formula for maxpool is still Output size= [(input size + (2xpadding) - kernel size)/stride] + 1
        #in this case: output = (input size - kernel size)/stride +1 since the padding is 0
        # (32-2)/2 + 1 = 16
        #the stride is 2 bc the parameters are (kernel size, stride)
        # output size is [N, 32, 16, 16]
        # you will get 32 filters, so that fulfills to N, 32, 
        # input size is 16
        # (16 + (2*1) - 3)/1 + 1 = 18-3 / 1 + 1 =  15+1 = 16
        #output size is [N, 32, 16, 16] 
        #relu is just an activation function max(0,1) so shape is the same [N, 32, 32, 32]
        #maxpool:
        # (16-2)/2 + 1 = 8 
        # [N, 32, 8, 8]
        # the linear layer self.fc1(x) is just taking the 2048 features and shaping them into 120 features 
        # [N, 120]


net = SimpleNet().to(device) #.to(device) send the define neural network to the specified device

"""Define the loss function and optimizer. Cross entropy loss is typically the default choice for classification problems. Again you can check Pytorch's documentation to see what optimizers you can use (there are plenty of them). Some common choices are SGD and adam."""

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(net.parameters(), lr=0.001) #0.001 is the default LR for Adam.

print(net)
"""Train the network. the number of epoch is set to 10 for quicker demonstration. In general you want to train for a bit longer until the network converges."""

net.train()
num_epochs = 15
for epoch in range(num_epochs):
    start_time = time.time()
    running_loss = 0.0
    correct = 0
    total = 0
    for i, data in enumerate(trainloader, 0):
        inputs, labels = data
        inputs = inputs.to(device)
        labels = labels.to(device)

        optimizer.zero_grad()
        outputs = net(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

        if i % 200 == 199 or i == len(trainloader)-1:
            # Print more information
            print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(trainloader)}], '
                  f'Loss: {running_loss / 200:.4f}, '
                  f'Accuracy: {100 * correct / total:.2f}%, '
                  f'Time: {time.time() - start_time:.2f}s')
            running_loss = 0.0
            correct = 0
            total = 0
            start_time = time.time()  # Reset timer


    net.eval()  # Set the model to evaluation mode
    val_correct = 0
    val_total = 0
    with torch.no_grad():  # No need to calculate gradients during validation
        for data in testloader:
            images, labels = data
            images = images.to(device)
            labels = labels.to(device)
            outputs = net(images)
            _, predicted = torch.max(outputs.data, 1)
            val_total += labels.size(0)
            val_correct += (predicted == labels).sum().item()

    val_accuracy = 100 * val_correct / val_total
    print(f'Epoch [{epoch + 1}/{num_epochs}], Validation Accuracy: {val_accuracy:.2f}%')

    net.train()  # Set the model back to training mode for the next epoch

print('Finished Training')


"""Test the trained network, typically called 'inference'."""

net.eval()
correct = 0
total = 0
with torch.no_grad():
    for data in testloader:
        images, labels = data
        images = images.to(device)
        labels = labels.to(device)
        outputs = net(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f}%')

"""Finally, save the network"""
torch.save(net.state_dict(), 'my_model.pth')
